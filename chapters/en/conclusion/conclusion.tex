\section{Performance Evaluation}

An Audio Plugin runs in an environment with many other components, sharing CPU resources. Processing of audio data must be completed within discrete time intervals dictated by the audio hardware. Typical audio sampling frequencies are 44.1kHz, 48kHz, 88.2kHz and 96kHz. Using 44.1kHz as an example, this means that all the calculations required for a single sample must be completed within 0,023 ms. Interrupts would be received from the audio hardware at intervals of 0.023ms as well, and this would put too much of a strain on the Operating System of the CPU though. Instead, requests for new audio data are bundled into buffers of samples. The size of the buffers is a parameter that the user can modify, it's usually set at 512 samples, but can be as low as 16 samples.

Increasing the buffer size, increases the amount of time that the CPU has to process audio data. This introduces latency into the system though. A buffer size of 512 samples equates to a latency of 11.60ms. A 16 sample buffer size equates to 0.36ms.

If a single plugin requires 1.0ms to complete its processing then it will not finish in time if the buffer size is set too low. If the buffer size is just high enough, then there still might not be enough CPU resources left for other plugins to complete their tasks.

\subsection{Synchronous Performance}

This project offloads the processing external SBC devices. However, no resources are saved if the audio plugin is blocked while it waits for the results from the SBC device. Since the external SBC devices are slower than the main CPU, the processing time will take longer. Adding the time it takes to serialise and deserialise the Datagram packet at each end will degrade performance even more.

Figure~\ref{fig:local_vs_remote} illustrates the problem in more detail.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{assets/conclusion/process_flow_compared.pdf}
    \caption{Local vs Remote Synchronous Processing}
    \label{fig:local_vs_remote}
\end{figure}

The example shows the audio hardware polling the operating system in intervals of 5.8 ms. This corresponds to a buffer size of 256 samples. The time interval between states D and E represents the time it takes for a plugin to process a buffer of 256 sample. The DAW  performs other necessary audio processing functions in the interval between F and G. After states G and H the DAW and OS are free to be able to do other things, like update the GUI.

With synchronous remote processing the state E is blocked until states 1 and 2 have completed. If that time is significant then the ability of the DAW and the OS to perform other critical tasks is impaired.

\input{chapters/en/conclusion/sync_results}

Table~\ref{tab:latency_comp} shows the measured times for various buffer sizes for the synchronous implementation that does no actually audio processing. Only the preparation transport times are taken into account. An audio system running with a buffer size of 64 samples has 1.451ms to complete all tasks. "rtTime" is the meassured total round trip time. This corresponds to the time between states D and E of the Synchronous Remote Process Flow diagram in Figure~\ref{fig:local_vs_remote}. "pTime" is time interval between states 1 and 2 on the SBC device, the time spent processing the data. In this case there was no processing so this is only the measures the time spent deserialiseing and serialising the datagrams into audio and midi data. "tTime" is the "rtTime" subtracted by the "pTime" and is the packaging overhead required to send and receive data.

The last column, "\% of limit", shows how much time was spent in total as a percentage of the limit. At a buffer size of 64 samples 39.59\% percent of the total time available was spent by a single plugin. This does not leave much time for other processes on the CPU. For a buffer size of 512 samples the "\% of limit" value is much lower. The total system latency is slightly higher that the stated 10ms maximum though. The synchronous implementation has not reduced the processing load on the CPU at all.


\subsection{Asynchronous Performance}

Instead of waiting for a response from the SBC device, as in the synchronous method above, the asynchronous method checks if a response is available. If so, return that data, if not immediately return without data. The initial request for audio data would return empty data, but by the time the second buffer is requested, the first respose from the SBC device might have returned. In both cases the only time spent by the audio plugin itself is the time is takes to serialise, deserialise, and transport the data. These are the intervals between the states D and E and M and N represented in figure~\ref{fig:async_remote}.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{assets/conclusion/async_flow.pdf}
    \caption{Local vs Remote Synchronous Processing}
    \label{fig:async_remote}
\end{figure}

By the time the second cycle begins (J in figure~\ref{fig:async_remote}) processed data from the first cycle has returned. The time between events M and N is no longer proportional to the amount of time needed to actually process the data, only to the time it takes for sending and receiving. Table~\ref{tab:latency_async} shows the measured times.

\input{chapters/en/conclusion/async_results}

In the table above "rtTime" is no longer the actual round trip total processing time. Since data is already available at the time the interrupt request is triggered, the plugin can return it's data immediately. This comes at the cost of a delay equal to one interrupt cycle, but the user can set the audio system's buffer size low enough that this is well below the 10ms limit, without needing to use more than 1.2\% of the processing time available.

The asynchronous method brings a real benefit to distributed processing in terms of lighting the load on the CPU. The price of the benefit though is an increase in the latency of the plugin. The processed audio data is always one delayed by one buffer cycle. Another disadvantage is that if several distributed processors are chained in series, as is the case in the demo application, then the latency is cumulative. This results in a total latency that is the limit time multiplied by the number of processors in the plugin.

\subsection{Potential Optimisations }

There are two areas of the application where unnecessary operations are performed and could be optimized. The first is the deserializsation of data when it is returned from the SBC. If serveral processes in the Plugin are chained in series, then the returned DiauproMessage could be sent directly to the following process without unnecessarily deserialising and the reserialising the data in between steps. This would be a relatively simple optimization to implement.

The second optimisation is similar but more complicated to implement. In a chain to processes the data would not need to be returned to the master plugin between each step, instead it could be sent to the next node directly. If the next node is located on the same SBC device then an additional hop over ethernet could be skipped as well. In addition serialisation steps between nodes could also be skipped if the nodes performed the operations directly on the data in the DiauproMessage. For this the DiauproMessage would need to be extended to include routing information so that each node knows the next destination point.

Although more complex, the second optimization would have the added benefit that the latency would no longer be a multiple of the full cycle time between interrupt calls. The final data could be gathered after a single cycle.


