\section{Realtime Audio Plugins}

Music composition and production is typically done with the assistance of a digital audio workstation (DAW) application. Midi events and audio recordings are arranged, mixed, edited, and processed. In order to make changes undo-able edits are made in a non-destructive fasion, calculated dynamically in realtime during audio playback. The original audio data is always preserved. The user can change the parameters of an effect or process in realtime and experiment with various parameters without fearing that the original audio recording might be permenantly altered.

A music sequencer or audio production application will usually include several built in realtime effects that a user can apply to an audio track. In addition to the built in options all professional applications will also be able to load 3d party effect plugins. Depending on the platform and vendor one or several available plugin standard will be implmeneted, the most common standard being Steinberg's VST standard.

Regardless of the standard most audio plugins function in a similar fashion. The host application will periodically poll the plugin via a callback, providing access to the source audio data stream and expecting the plugin to return the processed data.

Audio plugins can also provide a gui to the user that allows processing parameters to be modified, saved, and sequenced as well. This might be the cutoff frequency of a low pass filter, or the delay time of a reverb effect, for example.

From a programmer's point of view audio plugins are always compiled as dynamically loadable libraries that implement a standard's specific API. The host DAW application can load then at run time and stream audio data through them\cite{realtime-architectures}.On the Windows platform VST plugins are compiled to Dynamic Link Libraries, on Mac OSX they are Mach-O Bundles. The native apple Audio Unit plugins are also compiled as Mach-O bundles, they have almost identical functionality, but differ in their API implementation. Other alternative plugin formats are Avid's RTAS and AAX plugin formats, Microsoft's DirectX architecture, or LADSPA, DSSI and LV2 on Linux.

Realtime Audio Plugins, as the name implies, must be able to complete their tasks fast enough to comply with realtime audio requirements. How fast is fast enough? Well, that depends how you define "real time". In audio applications, real time is defined in terms of an audio system's latency. The total delay between the time an audio signal enters the system (at the analog to digital converter for example), is processed, and leaves the system (at the digital to analog conterver) is the latency. The maximum acceptable latency is considered to be around 10ms\cite{AES67-2013}. Any higher and the latency becomes disturbing and not acceptable for live performance applications.

Any process will introduce some amount of delay. However within the audio processing function, the programmer must take care not to introduce any unneccessary or uncalculateable delays. It's also important to understand that the audio processing function is working in the context of a high-proirity system thread. Nothing in the process should have to lock or wait for resources provided by other lower-priority threads. Examples of things to avoid are memory allocations or deallocation, waiting or locking a mutex conditional expressions inside loops that might break pipe-lining optimizations\cite{realtime-architectures}, or updating the graphic interface directly.

