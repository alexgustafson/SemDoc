\section{Audio via Ethernet}

Das Versenden von Audiodaten über Netzwerke ist nicht neu. Auch nicht das Senden von Audiodaten in Echtzeit. Das IETF (Internet Engineering Taskforce) RFC 3550 definiert das Real-time Transport Protocol für die Bereitstellung von Audio und Video in Echtzeit über IP-Netzwerke. RTP wird als Grundlage für die meisten Medien-Streaming und Video-Konferenz-Anwendungen eingesetzt.

Andere neue Spezifikationen wie AVB\footnote{Audio Video Bridging ist einer Sammplug IEEE standards welche Zeit-Synchroniziertes niedrig Latenz Streaming Dienste ermöglicht } und AES67\footnote{AES67 , ein von der Audio Engineering Society definierte Standard, die bestehenden Low-Latency Streaming-Systeme Interoperabilität ermöglicht. AES67 definieret keine neuen Technologien, sondern versucht, einen kleinsten gemeinsamen Nenner zu setzten, durch die bestehenden Standards kompatibel sein können. } bauen auf RTP und ermöglichen  präzises Timing und Synchronisieren für professionelle Audio-Anwendungen. Die Synchronisation ist in diesen Standards wichtig, weil sie sich mit der Steuerung von auf mehrere Hosts verteilter Audiohardware befassen.

Hardware-Synchronisation ist nicht für dieses Projekt relevant, weil es sich nicht mit externer Audio-Hardware befasst.  Ziel dieses Projektes ist es, externe CPUs als Audio-Koprozessoren über Gigabit-Ethernet zu nutzen.  Dennoch bieten die AVB- und AES67-Standards viele Erkenntnisse darüber, wie die Datenübertragung für Low-latency-Anwendungen optimiert werden kann und  beweisen deren Machbarkeit.  AES67 definiert Richtlinien, um Latenzzeiten deutlich unter 1 ms zu erreichen, auch bei Hunderten von parallel laufenden Audiostreams. Dies ist viel schneller als die in vielen DSP-basierten Systemen verwendeten Legacy-PCI- und Firewire-Verbindungen\cite{bouillot2009aes}.
