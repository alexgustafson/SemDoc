\section{Audio Over Ethernet}


Das Versenden von Audiodaten über Netzwerke ist nicht neu. Auch das Senden von Audiodaten in Echtzeit nicht. Das IETF (Internet Engineering Taskforce) RFC 3550 definitert das Real-time Transport Protocol für die Bereitstellung von Audio und Video in Echtzeit über IP-Netzwerke. RTP wird als Grundlage für die meisten Medien-Streaming und Video-Conferencing-Anwendungen eingesetzt.

Andere neue Spezifikationen wie AVB und AES67 bauen auf RTP und ermöglichen acurate Timing und Synchronisation für professionelle Audio-Anwendungen. Die Synchronisation ist in diesen Standards wichtig, weil sie sich mit der Steuerung von Audiohardware vetteilt auf mehreren Hosts befassen.

Hardware-Synchronisation ist nicht für dieses Projekt relevent, weil es sich nicht mit externen Audio-Hardware befasst. Das Ziel dieses Projektes ist es, externe CPUs als Audio-Koprozessoren über Gigabit-Ethernet zu nutzen. Trotzdem, die AVB und AES67 Standards bieten viele Erkenntnisse darüber, wie die Datenübertragung für Low-Latency-Anwendungen optimieret werden kann und ist ein Proof-of-Concept, dass es möglich ist. AES67 definiert Richtlinien um Latenzzeiten deutlich unter 1 ms zu erreichen, auch bei hunderte parallel laufende Audiostreams. Dies ist viel schneller als die Legacy-PCI und Firewire Verbindungen welche in vielen DSP-basierten Systemen verwendet worden\cite{bouillot2009aes}.