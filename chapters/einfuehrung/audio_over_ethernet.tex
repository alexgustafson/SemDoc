\section{Audio Over Ethernet}

Sending audio data over a network is not new. Sending audio data in "realtime" is also not new. The IETF ( Internet Engineering Task Force ) RFC 3550 Describes the Real-time Transport Protocol for delivering audio and video in real-time over IP networks. RTP however is mostly concerned with transmitting a few channels of media as quickly as possible over IP networks with lot of other traffic, reducing jitter (variations in latency) and providing Quality of Service strategies to achieve "acceptable" audio and video quality for streaming and conferencing purposes.

Other very recent specifications such as AVB\footnote{Audio Video Bridging refers to a set of IEEE standards that allow time-synchronized low latency streaming services } and AES67\footnote{AES67,created by the Audio Engineering Society, defines standard that allow existing low latency streaming systems to interoperate. AES67 does not define any new technologies but attempts to set a lowest common denominator by which existing standards can be compatible. } build on top of RTP and add more mechanisms to guarentee acurate timing and synchronization across a network for professional audio applications. The synchronisation is important in these standards because they are concerned with driving audio hardware attached to different hosts on a network.

Hardware synchronization and jitter management are not relevent to this project because we are not concerned with external audio hardware. The goal of this project it to utilise external CPUs as audio coprocessors connected via gigabit Ethernet. Even so, the AVB and AES67 standards offer many insights into how to optimize data transmission for low latency applications and they also offer a proof-of-concept that it is possible. The AES67 defines guidlines that can achieve latencies well below 1 ms for hundreds of simultaneos channels of high quality audio. This is much faster than the legacy PCI and Firewire rates used in many DSP based coprocessing systems\cite{bouillot2009aes}.
