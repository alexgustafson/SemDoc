\section{Audio Over Ethernet}

Sending audio data over a network is not new. Sending audio data in "realtime" is also not new. The IETF ( Internet Engineering Task Force ) RFC 3550 Describes the Real-time Transport Protocol for delivering audio and video in real-time over IP networks. RTP however is mostly concerned with transmitting a few channels of media as quickly as possible over IP networks with lot of other traffic, reducing jitter (variations in latency) and providing Quality of Service strategies to achieve "acceptable" audio and video quality for streaming and conferencing purposes.

Other specifications such as AVB\footnote{Audio Video Bridging refers to a set of IEEE standards that allow time-synchronized low latency streaming services } and AES67\footnote{AES67, created by the Audio Engineering Society, defines standard that allow existing low latency streaming systems to interoperate. AES67 does not define any new technologies but attempts to set a lowest common denominator by which existing standards can be compatible. } build on top of RTP and add more mechanisms to guarentee acurate timing and synchronization across a network for professional audio applications. The synchronisation is important is these applications because they are concerned with driving audio hardware attached to different hosts on a network.

Hardware synchronization and jitter management are not relevent to this project because we are not concerned with external audio hardware. The goal of this project it to utilise external cpus as audio coprocessors. Even so, the AVB and AES67 standards offer many insights into how to optimize data transmissionfor low latency applications and they also offer a proof-of-concept that it must be possible. The AES67 Specification's recomended packet times offer latencies well below 1 ms for hundred of simultaneos channels of high quality audio. This is well above legacy PCI and Firewire rates used for DSP based coprocessing\cite{bouillot2009aes}.
